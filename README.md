# TextCNN-Deep-learning
基于TextCNN实现新闻文本分类——深度学习与神经网络

项目背景：新闻发展越来越快，每天各种各样的新闻令人目不暇接，
对新闻进行科学的分类既能够方便不同的阅读群体根据需求快速选取自身感兴趣的新闻，也能够有效满足对海量的新闻素材提供科学的检索需求。
项目任务：赛题以新闻数据为赛题数据，整合划分出如下候选分类类别：财经、房产、教育、科技、军事、汽车、体育、游戏、娱乐和其他共十类的新闻文本数据。选手根据新闻标题和内容，进行分类。
1、输出分类的准确率不低于80%

2、能够输入单条新闻，输出新闻的分类，或者支持批量输入新闻，并输出新闻分类。

数据说明：本次训练使用了其中的10个分类（体育, 财经, 房产, 家居, 教育, 科技, 时尚, 时政, 游戏, 娱乐），每个分类6500条，总共65000条新闻数据。
数据集划分如下：
cnews.train.txt: 训练集(50000条)每类5000条
用于模型的参数的训练

cnews.val.txt: 验证集(5000条)每类500条
用于训练时检验模型的泛化能力

cnews.test.txt: 测试集(10000条)每类1000条
用于检验模型的分类效果

（数据集因体积过大，没有上传到GitHub）
模型介绍：
TextCNN包含四部分：词嵌入、卷积、池化、全连接+softmax.
文本矩阵。

Embedding：文本矩阵，每行词向量拼接得到对应的文本矩阵。图中维度为5。

Convolution：使用不同的卷积核（2，3，4），卷积核的宽度和词向量的长度一致，每个卷积核获得一列feature map。

MaxPolling：每个feature map通过 max-pooling都会得到一个特征值，这个操作也使得TextCNN能处理不同长度的文本。

FullConnection and Softmax：该层的输入为池化操作后形成的一维向量，经过激活函数Relu()输出，再加上Dropout层防止过拟合。将全连接层的输出使用softmax函数，获取文本分到不同类别的概率。

模型配置参数：

词向量维度：64

序列长度：600

类别数：10

卷积核数目：256

卷积核尺寸：5

词汇表大小：5000

全连接层神经元：128

dropout保留比例：0.5（随机生成的网络结构最多）

学习率：1e-3

每批训练大小：64

总迭代轮次：10
